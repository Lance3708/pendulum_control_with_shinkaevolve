--- a/original.py
+++ b/original.py
@@ -1,197 +1,279 @@
 import numpy as np
 
 # --- Physics Constants ---
 M_CART = 1.0       # Mass of the cart (kg)
 M_POLE = 0.35      # Mass of the pole (kg) - 更重，大幅增加控制难度
 L_POLE = 2.5       # Total length of the pole (m) - 更长，极不稳定
 L_COM = L_POLE / 2 # Length to center of mass (m)
 G = 9.81           # Gravity (m/s^2)
 FRICTION_CART = 0.35 # Coefficient of friction for cart - 高摩擦，更多能量损失
 FRICTION_JOINT = 0.25 # Coefficient of friction for joint - 高关节摩擦
 DT = 0.02          # Time step (s)
 MAX_STEPS = 1000   # 20 seconds simulation
 
 def simulate_pendulum_step(state, force, dt):
     """
     Simulates one time step of the Single Inverted Pendulum.
 
     State vector: [x, theta, dx, dtheta]
     - x: Cart position (m)
     - theta: Pole angle (rad), 0 is upright
     - dx: Cart velocity (m/s)
     - dtheta: Pole angular velocity (rad/s)
 
     Args:
         state: numpy array of shape (4,)
         force: scalar float, force applied to the cart (N)
         dt: float, time step (s)
 
     Returns:
         next_state: numpy array of shape (4,)
     """
     x, theta, dx, dtheta = state
 
     # Precompute trig terms
     sin_theta = np.sin(theta)
     cos_theta = np.cos(theta)
 
     # Equations of Motion (Non-linear)
     # derived from Lagrangian dynamics
 
     # Total mass
     M_total = M_CART + M_POLE
 
     # Friction forces
     f_cart = -FRICTION_CART * dx
     f_joint = -FRICTION_JOINT * dtheta
 
     # Denominator for solving linear system of accelerations
     # Derived from solving the system:
     # 1) (M+m)x_dd + (ml cos)theta_dd = F + f_cart + ml*theta_d^2*sin
     # 2) (ml cos)x_dd + (ml^2)theta_dd = mgl sin + f_joint
 
     temp = (force + f_cart + M_POLE * L_COM * dtheta**2 * sin_theta) / M_total
 
     theta_acc = (G * sin_theta - cos_theta * temp + f_joint / (M_POLE * L_COM)) / \
                 (L_COM * (4.0/3.0 - M_POLE * cos_theta**2 / M_total))
 
     x_acc = temp - (M_POLE * L_COM * theta_acc * cos_theta) / M_total
 
     # Euler integration
     next_x = x + dx * dt
     next_theta = theta + dtheta * dt
     next_dx = dx + x_acc * dt
     next_dtheta = dtheta + theta_acc * dt
 
     return np.array([next_x, next_theta, next_dx, next_dtheta])
 
 
 # EVOLVE-BLOCK-START
 class Controller:
     """
-    Adaptive LQR Controller with Velocity-Aware Gain Scheduling
-    Combines physically accurate friction modeling with intelligent gain adaptation
-    for ultra-fast stabilization while maintaining energy efficiency.
+    Adaptive Hybrid Controller with Phase-Based Control Strategies
+    
+    Implements three distinct control modes:
+    1. Energy-based swing-up for large angles
+    2. Blended transition control for medium angles
+    3. LQR + integral action for stabilization
     """
 
     def __init__(self):
         # System parameters
-        m = M_POLE
-        M = M_CART
-        l = L_COM
-        g = G
-        Mtot = M + m
-        denom0 = l * (4.0 / 3.0 - m / Mtot)
-        b_c = FRICTION_CART
-        b_j = FRICTION_JOINT
-
-        # Physically accurate linearized A matrix with corrected joint friction
+        self.m = M_POLE
+        self.M = M_CART
+        self.l = L_COM
+        self.g = G
+        self.Mtot = self.M + self.m
+        self.denom0 = self.l * (4.0 / 3.0 - self.m / self.Mtot)
+        
+        # Integral action variables
+        self.integral_x = 0.0
+        self.integral_theta = 0.0
+        
+        # Anti-windup limits
+        self.integral_limit = 5.0
+        
+        # Compute natural frequency for energy calculations
+        self.omega_n = np.sqrt(self.g / self.l)
+        
+        # Pre-compute LQR gains for stabilization mode
+        self._compute_lqr_gains()
+
+    def _compute_lqr_gains(self):
+        """Compute LQR gains for the stabilization mode"""
         A = np.zeros((4, 4))
         A[0, 2] = 1.0
         A[1, 3] = 1.0
-
-        # theta_acc row (3) - using corrected joint friction term matching simulator
-        A[3, 1] = g / denom0
-        A[3, 2] = b_c / (Mtot * denom0)
-        A[3, 3] = -b_j / (m * l * denom0)  # Matches simulator: f_joint/(m*l) / denom0
-
-        # x_acc row (2)
-        A[2, 1] = -(m * l / Mtot) * A[3, 1]
-        A[2, 2] = -b_c / Mtot - (m * l / Mtot) * A[3, 2]
-        A[2, 3] = b_j / (Mtot * denom0)
-
-        # B matrix
+        A[3, 1] = self.g / self.denom0
+        A[3, 2] = FRICTION_CART / (self.Mtot * self.denom0)
+        A[3, 3] = -FRICTION_JOINT / (self.m * self.l * self.denom0)
+        A[2, 1] = -(self.m * self.l / self.Mtot) * A[3, 1]
+        A[2, 2] = -FRICTION_CART / self.Mtot - (self.m * self.l / self.Mtot) * A[3, 2]
+        A[2, 3] = FRICTION_JOINT / (self.Mtot * self.denom0)
+
         B = np.zeros((4, 1))
-        B[2, 0] = 1.0 / Mtot + (m * l) / (Mtot**2 * denom0)
-        B[3, 0] = -1.0 / (Mtot * denom0)
-
-        # Proven optimal LQR weights from best performer (4920.14 score)
-        Q = np.diag([4.5, 44.0, 0.6, 3.2])
+        B[2, 0] = 1.0 / self.Mtot + (self.m * self.l) / (self.Mtot**2 * self.denom0)
+        B[3, 0] = -1.0 / (self.Mtot * self.denom0)
+
+        Q = np.diag([5.0, 50.0, 0.7, 3.5])  # Tuned for faster response
         R = np.array([[1.0]])
 
-        # Solve LQR gains
-        self.K = self.solve_lqr(A, B, Q, R)
-
-    def solve_lqr(self, A, B, Q, R):
-        """Solve continuous-time LQR"""
         from scipy.linalg import solve_continuous_are
         P = solve_continuous_are(A, B, Q, R)
-        K = np.linalg.inv(R) @ B.T @ P
-        return K
+        self.K_lqr = np.linalg.inv(R) @ B.T @ P
+
+    def _normalize_angle(self, theta):
+        """Robust angle normalization using arctan2"""
+        return np.arctan2(np.sin(theta), np.cos(theta))
+
+    def _compute_pendulum_energy(self, theta, dtheta):
+        """Compute total mechanical energy of the pendulum"""
+        T = 0.5 * self.m * (self.l**2) * (dtheta**2)  # Kinetic energy
+        V = self.m * self.g * self.l * (1 - np.cos(theta))  # Potential energy
+        return T + V
+
+    def _swing_up_control(self, state):
+        """Energy-based swing-up control for large angles"""
+        x, theta, dx, dtheta = state
+        
+        # Compute energy and desired energy (at upright position)
+        current_energy = self._compute_pendulum_energy(theta, dtheta)
+        desired_energy = 2 * self.m * self.g * self.l  # Energy at inverted position
+        
+        # Energy difference
+        energy_error = desired_energy - current_energy
+        
+        # Control law: proportional to energy error and angular velocity
+        # Sign ensures we add energy when needed
+        force = 20.0 * np.sign(dtheta * np.cos(theta)) * np.tanh(energy_error / 10.0)
+        
+        return force
+
+    def _transition_control(self, state):
+        """Blended control during transition from swing-up to stabilization"""
+        x, theta, dx, dtheta = state
+        
+        # Blend swing-up and LQR based on angle
+        blend_factor = np.tanh(5.0 * (abs(theta) - 0.3) / 0.2)  # Sharp transition around 0.3 rad
+        blend_factor = 0.5 * (1 + blend_factor)  # Map to [0, 1]
+        
+        # Get both control actions
+        swing_force = self._swing_up_control(state)
+        lqr_force = self._lqr_control(state)
+        
+        # Blend them
+        force = blend_factor * lqr_force + (1 - blend_factor) * swing_force
+        
+        return force
+
+    def _lqr_control(self, state):
+        """Standard LQR control with integral action"""
+        x, theta, dx, dtheta = state
+        
+        # Update integrals with anti-windup
+        self.integral_x += x * DT
+        self.integral_theta += theta * DT
+        
+        # Anti-windup protection
+        self.integral_x = np.clip(self.integral_x, -self.integral_limit, self.integral_limit)
+        self.integral_theta = np.clip(self.integral_theta, -self.integral_limit, self.integral_limit)
+        
+        # Extended state vector with integrals
+        state_vec = np.array([x, theta, dx, dtheta, self.integral_x, self.integral_theta])
+        
+        # Extended LQR gain matrix (adding integral action)
+        K_ext = np.zeros((1, 6))
+        K_ext[0, :4] = self.K_lqr[0, :]
+        
+        # Add integral gains (tuned for zero steady-state error)
+        K_ext[0, 4] = 0.8  # Integral gain for position
+        K_ext[0, 5] = 2.5  # Integral gain for angle
+        
+        force = -K_ext @ state_vec
+        
+        return force[0]
+
+    def _apply_nonlinear_modifications(self, force, state):
+        """Apply nonlinear modifications to control force"""
+        x, theta, dx, dtheta = state
+        
+        # Velocity-dependent damping augmentation
+        vel_damping = 0.3 * np.tanh(abs(dx) - 0.5) * dx
+        force -= vel_damping
+        
+        # Control authority scaling based on angle
+        authority_scaling = 1.0 - 0.3 * np.tanh(10.0 * abs(theta))
+        force *= authority_scaling
+        
+        return force
 
     def get_action(self, state):
-        """Adaptive LQR with additive swing-up assist for large angles"""
-        x, theta, dx, dtheta = state
-
-        # Normalize angle to [-pi, pi]
-        theta = ((theta + np.pi) % (2 * np.pi)) - np.pi
-
-        state_vec = np.array([x, theta, dx, dtheta])
-        base_force = -self.K @ state_vec
-
-        # Proven optimal gain scheduling from best performer
-        pos_gain = 1.0 + 0.5 * np.tanh(5.0 * max(0.0, abs(theta) - 0.6))
-        vel_gain = 1.0 + 0.3 * np.tanh(4.0 * max(0.0, abs(dtheta) - 1.0))
-
-        # Combined multiplicative gain
-        adaptive_gain = pos_gain * vel_gain
-
-        force = base_force * adaptive_gain
-
-        # Additive swing-up assist: only activates for large angles (>0.8 rad)
-        # Provides extra corrective impulse when pole is falling away from equilibrium
-        if abs(theta) > 0.8:
-            # Physics-informed assist: push cart in direction to catch falling pole
-            swing_activation = np.tanh(6.0 * (abs(theta) - 0.8))
-            # If theta*dtheta > 0, pole is falling further - need stronger correction
-            # Normalized by natural frequency of the pendulum for better scaling
-            natural_freq = np.sqrt(G / L_COM)
-            falling_factor = 1.0 + np.tanh(2.0 * theta * dtheta / (L_COM * natural_freq))
-            u_swing = 8.0 * swing_activation * np.sign(theta) * falling_factor
-            force = force + u_swing
-
-        return float(force[0])
+        """Main control function selecting appropriate control strategy"""
+        # Normalize angle for all computations
+        x, theta, dx, dtheta = state
+        theta = self._normalize_angle(theta)
+        normalized_state = np.array([x, theta, dx, dtheta])
+        
+        # Select control mode based on angle magnitude
+        abs_theta = abs(theta)
+        
+        if abs_theta > 0.5:
+            # Swing-up mode for large angles
+            force = self._swing_up_control(normalized_state)
+        elif abs_theta > 0.1:
+            # Transition mode for medium angles
+            force = self._transition_control(normalized_state)
+        else:
+            # Stabilization mode for small angles
+            force = self._lqr_control(normalized_state)
+            
+            # Apply additional nonlinear modifications near equilibrium
+            force = self._apply_nonlinear_modifications(force, normalized_state)
+        
+        # Final clipping to actuator limits
+        force = np.clip(force, -100.0, 100.0)
+        
+        return float(force)
 
 # Initialize controller
 controller = Controller()
 
 def get_control_action(state):
     force = controller.get_action(state)
-    # Apply force limits
     return float(np.clip(force, -100.0, 100.0))
 # EVOLVE-BLOCK-END
 
 def run_simulation(seed=None):
     """
     Runs the simulation loop.
     """
     if seed is not None:
         np.random.seed(seed)
 
     # Initial state: 0.4 rad (~23 degrees)
     # 更大初始角度配合更重更长的杆子，极具挑战性
     state = np.array([0.0, 0.9, 0.0, 0.0])
 
     states = [state]
     forces = []
 
     for _ in range(MAX_STEPS):
         force = get_control_action(state)
         # Clip force to realistic limits
         force = np.clip(force, -100.0, 100.0)
 
         next_state = simulate_pendulum_step(state, force, DT)
 
         states.append(next_state)
         forces.append(force)
 
         state = next_state
 
         # # Early termination checks
         # if np.any(np.isnan(state)):
         #     break
         # # Fail fast if it falls over (> 1.0 rad, matching evaluate.py)
         # if abs(state[1]) > 1.0:
         #     break
 
     return np.array(states), np.array(forces)