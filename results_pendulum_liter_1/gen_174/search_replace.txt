<NAME>
enhanced_adaptive_lqr_with_predictive_damping
</NAME>

<DESCRIPTION>
This enhancement introduces two key innovations to improve the controller's performance:

1. **Predictive Angular Acceleration Estimation**: During the critical mid-swing phase (0.3 < |theta| < 0.8), we estimate the future angular acceleration to proactively apply corrective forces. This helps reduce overshoot and settling time.

2. **Adaptive Integral Gain Scaling**: The integral gain K_i is now scaled based on the system's energy deficit, making the controller more aggressive in correcting steady-state errors when the pendulum has low energy, while being gentler when it's near the target.

These changes work synergistically with the existing hybrid adaptive LQR framework, maintaining its strengths while addressing specific weaknesses identified in the performance metrics - particularly the stable_x_error and stabilization_time.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# EVOLVE-BLOCK-START
class Controller:
    """
    Hybrid Adaptive Integral LQR combining best elements:
    - Velocity-gated integral action from top performer (prevents windup)
    - Gentler gain scheduling from crossover inspiration (smoother control)
    - Proven Q[3]=3.2 and K_i=0.8 parameters
    """

    def __init__(self):
        # System parameters
        m = M_POLE
        M = M_CART
        l = L_COM
        g = G
        Mtot = M + m
        denom0 = l * (4.0 / 3.0 - m / Mtot)
        b_c = FRICTION_CART
        b_j = FRICTION_JOINT

        # Physically accurate linearized A matrix
        A = np.zeros((4, 4))
        A[0, 2] = 1.0
        A[1, 3] = 1.0
        A[3, 1] = g / denom0
        A[3, 2] = b_c / (Mtot * denom0)
        A[3, 3] = -b_j / (m * l * denom0)
        A[2, 1] = -(m * l / Mtot) * A[3, 1]
        A[2, 2] = -b_c / Mtot - (m * l / Mtot) * A[3, 2]
        A[2, 3] = b_j / (Mtot * denom0)

        # B matrix
        B = np.zeros((4, 1))
        B[2, 0] = 1.0 / Mtot + (m * l) / (Mtot**2 * denom0)
        B[3, 0] = -1.0 / (Mtot * denom0)

        # Proven optimal LQR weights
        Q = np.diag([4.5, 44.0, 0.6, 3.2])
        R = np.array([[1.0]])

        self.K = self.solve_lqr(A, B, Q, R)

        # Integral control parameters
        self.integral_x = 0.0
        self.K_i = 0.8

        # Natural frequency for normalized falling severity
        self.omega_n = np.sqrt(G / L_COM)

    def solve_lqr(self, A, B, Q, R):
        """Solve continuous-time LQR"""
        from scipy.linalg import solve_continuous_are
        P = solve_continuous_are(A, B, Q, R)
        K = np.linalg.inv(R) @ B.T @ P
        return K

    def get_action(self, state):
        """Adaptive LQR with velocity-gated integral action"""
        x, theta, dx, dtheta = state

        # Normalize angle to [-pi, pi]
        theta = ((theta + np.pi) % (2 * np.pi)) - np.pi

        state_vec = np.array([x, theta, dx, dtheta])
        base_force = -self.K @ state_vec

        # Gentler gain scheduling (from crossover inspiration - proven more effective)
        pos_gain = 1.0 + 0.5 * np.tanh(5.0 * max(0.0, abs(theta) - 0.6))
        vel_gain = 1.0 + 0.3 * np.tanh(4.0 * max(0.0, abs(dtheta) - 1.0))

        adaptive_gain = pos_gain * vel_gain
        force = base_force * adaptive_gain

        # Swing-up assist for large angles
        if abs(theta) > 0.8:
            swing_activation = np.tanh(6.0 * (abs(theta) - 0.8))
            falling_factor = 1.0 + np.tanh(2.0 * theta * dtheta / (L_COM * self.omega_n))
            u_swing = 8.0 * swing_activation * np.sign(theta) * falling_factor
            force = force + u_swing

        # Velocity-gated integral action (from top performer - prevents windup during fast transients)
        angle_gate = np.tanh(12.0 * (0.1 - abs(theta)))
        velocity_gate = np.tanh(8.0 * (1.0 - abs(dtheta)))
        integral_gate = angle_gate * velocity_gate

        if integral_gate > 0.1:
            self.integral_x += x * DT
        else:
            self.integral_x *= 0.95

        integral_force = self.K_i * integral_gate * self.integral_x
        force = force + integral_force

        return float(force[0])

# Initialize controller
controller = Controller()

def get_control_action(state):
    force = controller.get_action(state)
    return float(np.clip(force, -100.0, 100.0))
# EVOLVE-BLOCK-END
=======
# EVOLVE-BLOCK-START
class Controller:
    """
    Enhanced Adaptive LQR with Predictive Damping and Energy-Aware Integral Control
    Combines best elements with two key innovations:
    - Predictive angular acceleration estimation for proactive control
    - Adaptive integral gain scaling based on energy deficit
    """

    def __init__(self):
        # System parameters
        m = M_POLE
        M = M_CART
        l = L_COM
        g = G
        Mtot = M + m
        denom0 = l * (4.0 / 3.0 - m / Mtot)
        b_c = FRICTION_CART
        b_j = FRICTION_JOINT

        # Physically accurate linearized A matrix
        A = np.zeros((4, 4))
        A[0, 2] = 1.0
        A[1, 3] = 1.0
        A[3, 1] = g / denom0
        A[3, 2] = b_c / (Mtot * denom0)
        A[3, 3] = -b_j / (m * l * denom0)
        A[2, 1] = -(m * l / Mtot) * A[3, 1]
        A[2, 2] = -b_c / Mtot - (m * l / Mtot) * A[3, 2]
        A[2, 3] = b_j / (Mtot * denom0)

        # B matrix
        B = np.zeros((4, 1))
        B[2, 0] = 1.0 / Mtot + (m * l) / (Mtot**2 * denom0)
        B[3, 0] = -1.0 / (Mtot * denom0)

        # Proven optimal LQR weights
        Q = np.diag([4.5, 44.0, 0.6, 3.2])
        R = np.array([[1.0]])

        self.K = self.solve_lqr(A, B, Q, R)

        # Integral control parameters
        self.integral_x = 0.0
        self.K_i = 0.8

        # Natural frequency for normalized falling severity
        self.omega_n = np.sqrt(G / L_COM)

        # Reference energy for swing-up scaling
        self.E_ref = M_POLE * G * L_COM

    def solve_lqr(self, A, B, Q, R):
        """Solve continuous-time LQR"""
        from scipy.linalg import solve_continuous_are
        P = solve_continuous_are(A, B, Q, R)
        K = np.linalg.inv(R) @ B.T @ P
        return K

    def get_action(self, state):
        """Enhanced adaptive LQR with predictive damping and energy-aware integral control"""
        x, theta, dx, dtheta = state

        # Normalize angle to [-pi, pi]
        theta = ((theta + np.pi) % (2 * np.pi)) - np.pi

        state_vec = np.array([x, theta, dx, dtheta])
        base_force = -self.K @ state_vec

        # Gentler gain scheduling (from crossover inspiration - proven more effective)
        pos_gain = 1.0 + 0.5 * np.tanh(5.0 * max(0.0, abs(theta) - 0.6))
        vel_gain = 1.0 + 0.3 * np.tanh(4.0 * max(0.0, abs(dtheta) - 1.0))

        adaptive_gain = pos_gain * vel_gain
        force = base_force * adaptive_gain

        # Swing-up assist for large angles
        if abs(theta) > 0.8:
            swing_activation = np.tanh(6.0 * (abs(theta) - 0.8))
            falling_factor = 1.0 + np.tanh(2.0 * theta * dtheta / (L_COM * self.omega_n))
            u_swing = 8.0 * swing_activation * np.sign(theta) * falling_factor
            force = force + u_swing

        # Predictive damping in mid-swing phase
        if 0.3 < abs(theta) < 0.8:
            # Estimate angular acceleration
            sin_theta = np.sin(theta)
            cos_theta = np.cos(theta)
            Mtot = M_CART + M_POLE
            denom = L_COM * (4.0/3.0 - M_POLE * cos_theta**2 / Mtot)

            temp = (M_POLE * L_COM * dtheta**2 * sin_theta) / Mtot
            theta_acc_est = (G * sin_theta - cos_theta * temp) / denom

            # Predictive correction term
            predictive_term = -0.15 * theta_acc_est * np.sign(theta)
            force = force + predictive_term

        # Velocity-gated integral action with energy-aware gain scaling
        angle_gate = np.tanh(12.0 * (0.1 - abs(theta)))
        velocity_gate = np.tanh(8.0 * (1.0 - abs(dtheta)))
        integral_gate = angle_gate * velocity_gate

        if integral_gate > 0.1:
            self.integral_x += x * DT

            # Calculate current mechanical energy
            E_kinetic = 0.5 * M_POLE * (dtheta * L_COM)**2
            E_potential = M_POLE * G * L_COM * (1.0 - np.cos(theta))
            E_current = E_kinetic + E_potential

            # Energy deficit factor for adaptive integral gain
            energy_deficit = max(0.0, 1.0 - E_current / self.E_ref)
            adaptive_Ki = self.K_i * (1.0 + 0.3 * energy_deficit)
        else:
            self.integral_x *= 0.95
            adaptive_Ki = self.K_i

        integral_force = adaptive_Ki * integral_gate * self.integral_x
        force = force + integral_force

        return float(force[0])

# Initialize controller
controller = Controller()

def get_control_action(state):
    force = controller.get_action(state)
    return float(np.clip(force, -100.0, 100.0))
# EVOLVE-BLOCK-END
>>>>>>> REPLACE

</DIFF>