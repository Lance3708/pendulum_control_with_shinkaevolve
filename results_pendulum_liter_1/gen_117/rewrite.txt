import numpy as np

# --- Physics Constants ---
M_CART = 1.0       # Mass of the cart (kg)
M_POLE = 0.35      # Mass of the pole (kg) - 更重，大幅增加控制难度
L_POLE = 2.5       # Total length of the pole (m) - 更长，极不稳定
L_COM = L_POLE / 2 # Length to center of mass (m)
G = 9.81           # Gravity (m/s^2)
FRICTION_CART = 0.35 # Coefficient of friction for cart - 高摩擦，更多能量损失
FRICTION_JOINT = 0.25 # Coefficient of friction for joint - 高关节摩擦
DT = 0.02          # Time step (s)
MAX_STEPS = 1000   # 20 seconds simulation

def simulate_pendulum_step(state, force, dt):
    """
    Simulates one time step of the Single Inverted Pendulum.

    State vector: [x, theta, dx, dtheta]
    - x: Cart position (m)
    - theta: Pole angle (rad), 0 is upright
    - dx: Cart velocity (m/s)
    - dtheta: Pole angular velocity (rad/s)

    Args:
        state: numpy array of shape (4,)
        force: scalar float, force applied to the cart (N)
        dt: float, time step (s)

    Returns:
        next_state: numpy array of shape (4,)
    """
    x, theta, dx, dtheta = state

    # Precompute trig terms
    sin_theta = np.sin(theta)
    cos_theta = np.cos(theta)

    # Equations of Motion (Non-linear)
    # derived from Lagrangian dynamics

    # Total mass
    M_total = M_CART + M_POLE

    # Friction forces
    f_cart = -FRICTION_CART * dx
    f_joint = -FRICTION_JOINT * dtheta

    # Denominator for solving linear system of accelerations
    # Derived from solving the system:
    # 1) (M+m)x_dd + (ml cos)theta_dd = F + f_cart + ml*theta_d^2*sin
    # 2) (ml cos)x_dd + (ml^2)theta_dd = mgl sin + f_joint

    temp = (force + f_cart + M_POLE * L_COM * dtheta**2 * sin_theta) / M_total

    theta_acc = (G * sin_theta - cos_theta * temp + f_joint / (M_POLE * L_COM)) / \
                (L_COM * (4.0/3.0 - M_POLE * cos_theta**2 / M_total))

    x_acc = temp - (M_POLE * L_COM * theta_acc * cos_theta) / M_total

    # Euler integration
    next_x = x + dx * dt
    next_theta = theta + dtheta * dt
    next_dx = dx + x_acc * dt
    next_dtheta = dtheta + theta_acc * dt

    return np.array([next_x, next_theta, next_dx, next_dtheta])


# EVOLVE-BLOCK-START
class Controller:
    """
    Phase-Aware Adaptive LQR with Integral Correction
    Implements a three-phase control strategy with smooth transitions:
    1. RECOVERY: Aggressive swing-up with predictive correction
    2. TRANSITION: Smooth blend to precision control
    3. PRECISION: High-accuracy LQR with gated integral action
    """

    def __init__(self):
        # System parameters
        m = M_POLE
        M = M_CART
        l = L_COM
        g = G
        Mtot = M + m
        denom0 = l * (4.0 / 3.0 - m / Mtot)
        b_c = FRICTION_CART
        b_j = FRICTION_JOINT

        # Continuous-time A matrix with friction
        A = np.zeros((4, 4))
        A[0, 2] = 1.0
        A[1, 3] = 1.0
        A[3, 1] = g / denom0
        A[3, 2] = b_c / (Mtot * denom0)
        A[3, 3] = -b_j / (m * l * denom0)
        A[2, 1] = -(m * l / Mtot) * A[3, 1]
        A[2, 2] = -b_c / Mtot - (m * l / Mtot) * A[3, 2]
        A[2, 3] = b_j / (Mtot * denom0)

        # B matrix
        B = np.zeros((4, 1))
        B[2, 0] = 1.0 / Mtot + (m * l) / (Mtot**2 * denom0)
        B[3, 0] = -1.0 / (Mtot * denom0)

        # Optimized LQR weights
        Q = np.diag([4.5, 44.0, 0.6, 3.2])
        R = np.array([[1.0]])

        # Solve LQR gains
        self.K = self.solve_lqr(A, B, Q, R)
        
        # Natural frequency for physics-informed scaling
        self.omega_n = np.sqrt(G / L_COM)
        
        # Integral state with anti-windup
        self.integral_x = 0.0
        self.k_i = 0.025

    def solve_lqr(self, A, B, Q, R):
        """Solve continuous-time LQR"""
        from scipy.linalg import solve_continuous_are
        P = solve_continuous_are(A, B, Q, R)
        K = np.linalg.inv(R) @ B.T @ P
        return K

    def get_action(self, state):
        x, theta, dx, dtheta = state

        # Robust angle normalization
        theta_norm = np.arctan2(np.sin(theta), np.cos(theta))
        abs_theta = abs(theta_norm)

        state_vec = np.array([x, theta_norm, dx, dtheta])
        base_force = -self.K @ state_vec

        if abs_theta > 0.5:
            # RECOVERY PHASE: Aggressive swing-up
            swing_activation = np.tanh(5.0 * (abs_theta - 0.5))
            falling_severity = 1.0 + 0.6 * np.tanh(2.5 * theta_norm * dtheta)
            u_swing = 10.0 * swing_activation * np.sign(theta_norm) * falling_severity
            
            # Velocity boost for rapid recovery
            vel_boost = 1.0 + 0.4 * np.tanh(3.0 * max(0.0, abs(dtheta) - 0.8))
            
            force = base_force * vel_boost + u_swing
            self.integral_x = 0.0  # Reset integral
            
        elif abs_theta > 0.1:
            # TRANSITION PHASE: Smooth blend
            blend_factor = (abs_theta - 0.1) / 0.4
            adaptive_gain = 1.0 + 0.25 * blend_factor * np.tanh(4.0 * abs_theta)
            force = base_force * adaptive_gain
            self.integral_x *= 0.95  # Gradual decay
            
        else:
            # PRECISION PHASE: Zero steady-state error
            integral_gate = np.tanh(15.0 * (0.1 - abs_theta))
            self.integral_x += x * DT * integral_gate
            self.integral_x = np.clip(self.integral_x, -2.0, 2.0)  # Anti-windup
            force = base_force + self.k_i * self.integral_x

        return float(force[0])

# Initialize controller
controller = Controller()

def get_control_action(state):
    force = controller.get_action(state)
    return float(np.clip(force, -100.0, 100.0))
# EVOLVE-BLOCK-END

def run_simulation(seed=None):
    """
    Runs the simulation loop.
    """
    if seed is not None:
        np.random.seed(seed)

    # Initial state: 0.4 rad (~23 degrees)
    # 更大初始角度配合更重更长的杆子，极具挑战性
    state = np.array([0.0, 0.9, 0.0, 0.0])

    states = [state]
    forces = []

    for _ in range(MAX_STEPS):
        force = get_control_action(state)
        # Clip force to realistic limits
        force = np.clip(force, -100.0, 100.0)

        next_state = simulate_pendulum_step(state, force, DT)

        states.append(next_state)
        forces.append(force)

        state = next_state

    return np.array(states), np.array(forces)