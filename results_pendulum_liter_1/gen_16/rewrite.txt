import numpy as np

# --- Physics Constants ---
M_CART = 1.0       # Mass of the cart (kg)
M_POLE = 0.35      # Mass of the pole (kg) - 更重，大幅增加控制难度
L_POLE = 2.5       # Total length of the pole (m) - 更长，极不稳定
L_COM = L_POLE / 2 # Length to center of mass (m)
G = 9.81           # Gravity (m/s^2)
FRICTION_CART = 0.35 # Coefficient of friction for cart - 高摩擦，更多能量损失
FRICTION_JOINT = 0.25 # Coefficient of friction for joint - 高关节摩擦
DT = 0.02          # Time step (s)
MAX_STEPS = 1000   # 20 seconds simulation

def simulate_pendulum_step(state, force, dt):
    """
    Simulates one time step of the Single Inverted Pendulum.

    State vector: [x, theta, dx, dtheta]
    - x: Cart position (m)
    - theta: Pole angle (rad), 0 is upright
    - dx: Cart velocity (m/s)
    - dtheta: Pole angular velocity (rad/s)

    Args:
        state: numpy array of shape (4,)
        force: scalar float, force applied to the cart (N)
        dt: float, time step (s)

    Returns:
        next_state: numpy array of shape (4,)
    """
    x, theta, dx, dtheta = state

    # Precompute trig terms
    sin_theta = np.sin(theta)
    cos_theta = np.cos(theta)

    # Equations of Motion (Non-linear)
    # derived from Lagrangian dynamics

    # Total mass
    M_total = M_CART + M_POLE

    # Friction forces
    f_cart = -FRICTION_CART * dx
    f_joint = -FRICTION_JOINT * dtheta

    # Denominator for solving linear system of accelerations
    temp = (force + f_cart + M_POLE * L_COM * dtheta**2 * sin_theta) / M_total

    theta_acc = (G * sin_theta - cos_theta * temp + f_joint / (M_POLE * L_COM)) / \
                (L_COM * (4.0/3.0 - M_POLE * cos_theta**2 / M_total))

    x_acc = temp - (M_POLE * L_COM * theta_acc * cos_theta) / M_total

    # Euler integration
    next_x = x + dx * dt
    next_theta = theta + dtheta * dt
    next_dx = dx + x_acc * dt
    next_dtheta = dtheta + theta_acc * dt

    return np.array([next_x, next_theta, next_dx, next_dtheta])


# EVOLVE-BLOCK-START
class Controller:
    """
    Advanced LQR Controller with Friction-Aware Modeling and Optimized Weights.
    
    Key improvements:
    1. Friction-aware linearized model includes damping in A matrix
    2. Aggressive weight tuning for maximum speed and efficiency
    3. Semi-implicit state estimation for better feedback
    4. High-precision stabilization
    """

    def __init__(self):
        # System parameters
        m = M_POLE      # pole mass
        M = M_CART      # cart mass  
        l = L_COM       # distance to COM
        g = G           # gravity
        b = FRICTION_CART     # cart friction coefficient
        c = FRICTION_JOINT    # joint friction coefficient
        
        # Enhanced linearized state space model including friction terms
        # A = [∂ẋ/∂x, ∂ẋ/∂θ, ∂ẋ/∂ẋ, ∂ẋ/∂θ̇]
        # This correction is crucial for high-friction systems
        A = np.array([
            [0, 0, 1, 0],
            [0, 0, 0, 1],
            [0, -m*g/M, -b/M, 0],
            [0, (m+M)*g/(M*l), -c/(M*l), 0]
        ])
        
        B = np.array([
            [0],
            [0],
            [1/M],
            [-1/(M*l)]
        ])
        
        # Optimized LQR weights through constrained parameter search
        # High Q weights on states to drive fast convergence
        # Low R weight to allow aggressive control when needed
        Q = np.diag([12.0, 45.0, 0.8, 3.0])    # Emphasize rapid error reduction
        R = np.array([[0.8]])                  # Allow stronger forces for faster response
        
        # Solve LQR problem
        self.K = self.solve_lqr(A, B, Q, R)
        
    def solve_lqr(self, A, B, Q, R):
        """Solve continuous-time LQR problem"""
        from scipy.linalg import solve_continuous_are
        P = solve_continuous_are(A, B, Q, R)
        K = np.linalg.inv(R) @ B.T @ P
        return K
    
    def get_action(self, state):
        """Enhanced LQR control law with semi-implicit update and angle normalization"""
        x, theta, dx, dtheta = state
        
        # Normalize angle to [-π, π] for consistent feedback
        theta = ((theta + np.pi) % (2 * np.pi)) - np.pi
        
        # Use semi-implicit thinking: future state estimate for feedback
        # This doesn't affect simulation, just makes control law slightly more predictive
        # without adding complexity
        estimated_x = x + dx * DT * 0.5
        estimated_dx = dx
        estimated_dtheta = dtheta
        
        state_vec = np.array([estimated_x, theta, estimated_dx, estimated_dtheta])
        force = -self.K @ state_vec
        return float(force[0])

# Initialize controller  
controller = Controller()

def get_control_action(state):
    return float(controller.get_action(state))
# EVOLVE-BLOCK-END

def run_simulation(seed=None):
    """
    Runs the simulation loop.
    """
    if seed is not None:
        np.random.seed(seed)

    # Initial state: large angle challenge
    state = np.array([0.0, 0.9, 0.0, 0.0])

    states = [state]
    forces = []

    for _ in range(MAX_STEPS):
        force = get_control_action(state)
        # Clip force to realistic limits
        force = np.clip(force, -100.0, 100.0)

        next_state = simulate_pendulum_step(state, force, DT)

        states.append(next_state)
        forces.append(force)

        state = next_state

    return np.array(states), np.array(forces)