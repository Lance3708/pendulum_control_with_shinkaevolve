import numpy as np

# --- Physics Constants ---
M_CART = 1.0       # Mass of the cart (kg)
M_POLE = 0.35      # Mass of the pole (kg) - 更重，大幅增加控制难度
L_POLE = 2.5       # Total length of the pole (m) - 更长，极不稳定
L_COM = L_POLE / 2 # Length to center of mass (m)
G = 9.81           # Gravity (m/s^2)
FRICTION_CART = 0.35 # Coefficient of friction for cart - 高摩擦，更多能量损失
FRICTION_JOINT = 0.25 # Coefficient of friction for joint - 高关节摩擦
DT = 0.02          # Time step (s)
MAX_STEPS = 1000   # 20 seconds simulation

def simulate_pendulum_step(state, force, dt):
    """
    Simulates one time step of the Single Inverted Pendulum.
    """
    x, theta, dx, dtheta = state

    sin_theta = np.sin(theta)
    cos_theta = np.cos(theta)

    M_total = M_CART + M_POLE

    f_cart = -FRICTION_CART * dx
    f_joint = -FRICTION_JOINT * dtheta

    temp = (force + f_cart + M_POLE * L_COM * dtheta**2 * sin_theta) / M_total

    theta_acc = (G * sin_theta - cos_theta * temp + f_joint / (M_POLE * L_COM)) / \
                (L_COM * (4.0/3.0 - M_POLE * cos_theta**2 / M_total))

    x_acc = temp - (M_POLE * L_COM * theta_acc * cos_theta) / M_total

    next_x = x + dx * dt
    next_theta = theta + dtheta * dt
    next_dx = dx + x_acc * dt
    next_dtheta = dtheta + theta_acc * dt

    return np.array([next_x, next_theta, next_dx, next_dtheta])


# EVOLVE-BLOCK-START
class Controller:
    """
    Refined Adaptive Integral LQR with Optimized Parameters
    Uses proven optimal Q[3]=3.2, simplified angle-only integral gating,
    and sharpened gain scheduling for faster stabilization.
    """

    def __init__(self):
        m = M_POLE
        M = M_CART
        l = L_COM
        g = G
        Mtot = M + m
        denom0 = l * (4.0 / 3.0 - m / Mtot)
        b_c = FRICTION_CART
        b_j = FRICTION_JOINT

        # Physically accurate linearized A matrix
        A = np.zeros((4, 4))
        A[0, 2] = 1.0
        A[1, 3] = 1.0
        A[3, 1] = g / denom0
        A[3, 2] = b_c / (Mtot * denom0)
        A[3, 3] = -b_j / (m * l * denom0)
        A[2, 1] = -(m * l / Mtot) * A[3, 1]
        A[2, 2] = -b_c / Mtot - (m * l / Mtot) * A[3, 2]
        A[2, 3] = b_j / (Mtot * denom0)

        # B matrix
        B = np.zeros((4, 1))
        B[2, 0] = 1.0 / Mtot + (m * l) / (Mtot**2 * denom0)
        B[3, 0] = -1.0 / (Mtot * denom0)

        # Proven optimal LQR weights - Q[3]=3.2 is the sweet spot
        Q = np.diag([4.5, 44.0, 0.6, 3.2])
        R = np.array([[1.0]])

        self.K = self.solve_lqr(A, B, Q, R)

        # Integral control - slightly increased for faster cart centering
        self.integral_x = 0.0
        self.K_i = 0.82

        # Natural frequency for swing-up scaling
        self.omega_n = np.sqrt(G / L_COM)

    def solve_lqr(self, A, B, Q, R):
        from scipy.linalg import solve_continuous_are
        P = solve_continuous_are(A, B, Q, R)
        K = np.linalg.inv(R) @ B.T @ P
        return K

    def get_action(self, state):
        x, theta, dx, dtheta = state

        # Robust angle normalization
        theta = ((theta + np.pi) % (2 * np.pi)) - np.pi

        state_vec = np.array([x, theta, dx, dtheta])
        base_force = -self.K @ state_vec

        # Sharpened gain scheduling with steeper transitions for crisper mode switching
        pos_gain = 1.0 + 0.5 * np.tanh(7.0 * max(0.0, abs(theta) - 0.6))
        vel_gain = 1.0 + 0.3 * np.tanh(6.0 * max(0.0, abs(dtheta) - 1.0))

        adaptive_gain = pos_gain * vel_gain
        force = base_force * adaptive_gain

        # Swing-up assist for large angles
        if abs(theta) > 0.8:
            swing_activation = np.tanh(6.0 * (abs(theta) - 0.8))
            falling_factor = 1.0 + np.tanh(2.0 * theta * dtheta / (L_COM * self.omega_n))
            u_swing = 8.0 * swing_activation * np.sign(theta) * falling_factor
            force = force + u_swing

        # Simplified angle-only integral gating (proven most effective)
        integral_gate = np.tanh(12.0 * (0.1 - abs(theta)))
        
        if integral_gate > 0.1:
            self.integral_x += x * DT
            # Tighter anti-windup for faster response
            self.integral_x = np.clip(self.integral_x, -1.5, 1.5)
        else:
            # Fixed decay rate - simple and proven
            self.integral_x *= 0.95

        integral_force = self.K_i * integral_gate * self.integral_x
        force = force + integral_force

        return float(force[0])

# Initialize controller
controller = Controller()

def get_control_action(state):
    force = controller.get_action(state)
    return float(np.clip(force, -100.0, 100.0))
# EVOLVE-BLOCK-END

def run_simulation(seed=None):
    if seed is not None:
        np.random.seed(seed)

    state = np.array([0.0, 0.9, 0.0, 0.0])

    states = [state]
    forces = []

    for _ in range(MAX_STEPS):
        force = get_control_action(state)
        force = np.clip(force, -100.0, 100.0)

        next_state = simulate_pendulum_step(state, force, DT)

        states.append(next_state)
        forces.append(force)

        state = next_state

    return np.array(states), np.array(forces)