--- a/original.py
+++ b/original.py
@@ -1,169 +1,222 @@
 import numpy as np
 
 # --- Physics Constants ---
 M_CART = 1.0       # Mass of the cart (kg)
 M_POLE = 0.35      # Mass of the pole (kg) - 更重，大幅增加控制难度
 L_POLE = 2.5       # Total length of the pole (m) - 更长，极不稳定
 L_COM = L_POLE / 2 # Length to center of mass (m)
 G = 9.81           # Gravity (m/s^2)
 FRICTION_CART = 0.35 # Coefficient of friction for cart - 高摩擦，更多能量损失
 FRICTION_JOINT = 0.25 # Coefficient of friction for joint - 高关节摩擦
 DT = 0.02          # Time step (s)
 MAX_STEPS = 1000   # 20 seconds simulation
 
 def simulate_pendulum_step(state, force, dt):
     """
     Simulates one time step of the Single Inverted Pendulum.
 
     State vector: [x, theta, dx, dtheta]
     - x: Cart position (m)
     - theta: Pole angle (rad), 0 is upright
     - dx: Cart velocity (m/s)
     - dtheta: Pole angular velocity (rad/s)
 
     Args:
         state: numpy array of shape (4,)
         force: scalar float, force applied to the cart (N)
         dt: float, time step (s)
 
     Returns:
         next_state: numpy array of shape (4,)
     """
     x, theta, dx, dtheta = state
 
     # Precompute trig terms
     sin_theta = np.sin(theta)
     cos_theta = np.cos(theta)
 
     # Equations of Motion (Non-linear)
     # derived from Lagrangian dynamics
 
     # Total mass
     M_total = M_CART + M_POLE
 
     # Friction forces
     f_cart = -FRICTION_CART * dx
     f_joint = -FRICTION_JOINT * dtheta
 
     # Denominator for solving linear system of accelerations
     # Derived from solving the system:
     # 1) (M+m)x_dd + (ml cos)theta_dd = F + f_cart + ml*theta_d^2*sin
     # 2) (ml cos)x_dd + (ml^2)theta_dd = mgl sin + f_joint
 
     temp = (force + f_cart + M_POLE * L_COM * dtheta**2 * sin_theta) / M_total
 
     theta_acc = (G * sin_theta - cos_theta * temp + f_joint / (M_POLE * L_COM)) / \
                 (L_COM * (4.0/3.0 - M_POLE * cos_theta**2 / M_total))
 
     x_acc = temp - (M_POLE * L_COM * theta_acc * cos_theta) / M_total
 
     # Euler integration
     next_x = x + dx * dt
     next_theta = theta + dtheta * dt
     next_dx = dx + x_acc * dt
     next_dtheta = dtheta + theta_acc * dt
 
     return np.array([next_x, next_theta, next_dx, next_dtheta])
 
 
 # EVOLVE-BLOCK-START
 class Controller:
     """
-    Suboptimal LQR Controller for Single Inverted Pendulum Stabilization.
-    次优LQR控制器 - 能稳住，但参数故意调得"懒惰"。
-
-    特点：
-    1. 物理环境更难（杆更长更重，摩擦更大）。
-    2. Q矩阵参数较小：对误差容忍度高 -> 精度分低。
-    3. R矩阵参数较大：不愿用大力 -> 响应慢，时间分低。
-
-    目标：初始分数 ~3000 分，进化后可达 9000+ 分。
+    Advanced Nonlinear Controller for Single Inverted Pendulum Stabilization.
+
+    Features:
+    1. Energy-based swing-up control for large angles
+    2. Nonlinear LQR with state-dependent gains for stabilization
+    3. Smooth transition between controllers
     """
 
     def __init__(self):
-        # 系统参数
-        m = M_POLE  # 摆杆质量
-        M = M_CART  # 小车质量
-        l = L_COM   # 质心距离
-        g = G       # 重力加速度
-
-        # 线性化状态空间模型
+        # System parameters
+        self.m = M_POLE  # Pole mass
+        self.M = M_CART  # Cart mass
+        self.l = L_COM   # Length to COM
+        self.g = G       # Gravity
+
+        # Pre-compute constant terms
+        self.total_mass = self.M + self.m
+        self.ml = self.m * self.l
+
+        # Design multiple LQR controllers for different operating points
+        self.K_upright = self.design_lqr_controller(100, 1000, 50, 100, 0.1)  # High gain for stabilization
+        self.K_swing = self.design_lqr_controller(1, 1, 0.1, 0.1, 1.0)       # Low gain for swing-up
+
+    def design_lqr_controller(self, qx, qtheta, qdx, qdtheta, r):
+        """Design LQR controller with given weights"""
         A = np.array([
             [0, 0, 1, 0],
             [0, 0, 0, 1],
-            [0, -m*g/M, 0, 0],
-            [0, (m+M)*g/(M*l), 0, 0]
+            [0, -self.m*self.g/self.M, 0, 0],
+            [0, (self.m+self.M)*self.g/(self.M*self.l), 0, 0]
         ])
 
         B = np.array([
             [0],
             [0],
-            [1/M],
-            [-1/(M*l)]
+            [1/self.M],
+            [-1/(self.M*self.l)]
         ])
 
-        # LQR权重矩阵（更保守的次优设置，留出充分进化空间）
-        # Q: 显著降低权重，高度容忍误差 - 导致基础分数低
-        # R: 大幅增加权重，极度限制出力 - 导致响应慢，能耗高
-        Q = np.diag([2.0, 8.0, 0.05, 0.4])    # [x, theta, dx, dtheta] (更保守)
-        R = np.array([[3.0]])                  # 控制力惩罚极大 (非常不愿意用大力)
-
-        # 求解LQR增益
-        self.K = self.solve_lqr(A, B, Q, R)
-
-    def solve_lqr(self, A, B, Q, R):
-        """求解连续时间LQR问题"""
+        Q = np.diag([qx, qtheta, qdx, qdtheta])
+        R = np.array([[r]])
+
         from scipy.linalg import solve_continuous_are
         P = solve_continuous_are(A, B, Q, R)
         K = np.linalg.inv(R) @ B.T @ P
         return K
 
+    def energy_shaping_control(self, state):
+        """Energy-based control for swing-up"""
+        x, theta, dx, dtheta = state
+
+        # Calculate total mechanical energy
+        # Potential energy (reference at bottom position)
+        pe = self.m * self.g * self.l * (1 - np.cos(theta))
+        # Kinetic energy
+        ke = 0.5 * self.M * dx**2 + 0.5 * self.m * (dx**2 + (self.l * dtheta)**2 + 2*dx*self.l*dtheta*np.cos(theta))
+        total_energy = pe + ke
+
+        # Desired energy for upright position (at rest)
+        desired_energy = 2 * self.m * self.g * self.l
+
+        # Energy error
+        energy_error = desired_energy - total_energy
+
+        # Control law: proportional to energy error and angular velocity
+        # This drives the system toward the homoclinic orbit
+        force = 0.5 * energy_error * dtheta * np.cos(theta)
+
+        return np.clip(force, -100, 100)
+
+    def nonlinear_lqr_control(self, state):
+        """Nonlinear LQR with state-dependent gains"""
+        x, theta, dx, dtheta = state
+
+        # Normalize angle to [-pi, pi]
+        theta = ((theta + np.pi) % (2 * np.pi)) - np.pi
+
+        # State-dependent gain scheduling
+        # Increase gains as we get closer to upright
+        angle_factor = np.exp(-5 * np.abs(theta))  # High gain near upright
+        velocity_factor = np.exp(-0.1 * (dx**2 + dtheta**2))  # Reduce gains at high velocities
+
+        # Interpolate between swing-up and stabilization gains
+        K = angle_factor * self.K_upright + (1 - angle_factor) * self.K_swing
+
+        state_vec = np.array([x, theta, dx, dtheta])
+        force = -K @ state_vec
+
+        return np.clip(float(force), -100, 100)
+
     def get_action(self, state):
-        """LQR控制法则: u = -K * x"""
+        """Hybrid control strategy"""
         x, theta, dx, dtheta = state
+
+        # Normalize angle
         theta = ((theta + np.pi) % (2 * np.pi)) - np.pi
-        state_vec = np.array([x, theta, dx, dtheta])
-        force = -self.K @ state_vec
-        return float(force[0])
+
+        # Calculate total energy
+        pe = self.m * self.g * self.l * (1 - np.cos(theta))
+        ke = 0.5 * self.M * dx**2 + 0.5 * self.m * (dx**2 + (self.l * dtheta)**2 + 2*dx*self.l*dtheta*np.cos(theta))
+        total_energy = pe + ke
+        desired_energy = 2 * self.m * self.g * self.l
+
+        # Use energy shaping for large deviations
+        if np.abs(theta) > 0.3 or np.abs(total_energy - desired_energy) > 1.0:
+            return self.energy_shaping_control(state)
+        else:
+            # Switch to nonlinear LQR for stabilization
+            return self.nonlinear_lqr_control(state)
 
 # Initialize controller
 controller = Controller()
 
 def get_control_action(state):
     return float(controller.get_action(state))
 # EVOLVE-BLOCK-END
 
 def run_simulation(seed=None):
     """
     Runs the simulation loop.
     """
     if seed is not None:
         np.random.seed(seed)
 
     # Initial state: 0.4 rad (~23 degrees)
     # 更大初始角度配合更重更长的杆子，极具挑战性
     state = np.array([0.0, 0.9, 0.0, 0.0])
 
     states = [state]
     forces = []
 
     for _ in range(MAX_STEPS):
         force = get_control_action(state)
         # Clip force to realistic limits
         force = np.clip(force, -100.0, 100.0)
 
         next_state = simulate_pendulum_step(state, force, DT)
 
         states.append(next_state)
         forces.append(force)
 
         state = next_state
 
         # # Early termination checks
         # if np.any(np.isnan(state)):
         #     break
         # # Fail fast if it falls over (> 1.0 rad, matching evaluate.py)
         # if abs(state[1]) > 1.0:
         #     break
 
     return np.array(states), np.array(forces)