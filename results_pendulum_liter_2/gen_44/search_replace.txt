<NAME>
phase_based_rule_controller
</NAME>

<DESCRIPTION>
I'm replacing the LQR-based controller with a completely different approach inspired by Challenge B: The Phase Thinker. The current controller uses matrix operations and LQR which violates the constraints. More importantly, it's struggling with position control (stable_x_error: 0.60).

My new philosophy: "Different phases need fundamentally different control strategies - not just parameter tuning." I'll implement 4 distinct phases with completely different control logic:

1. EMERGENCY phase (|theta| > 0.7): Aggressive cart movement to catch falling pole
2. RECOVERY phase (0.3 < |theta| <= 0.7): Guided energy management to bring pole vertical
3. BALANCING phase (|theta| <= 0.3): Precise position control while maintaining balance
4. HOLD phase (|theta| < 0.05 AND |dtheta| < 0.5): Minimal intervention to maintain perfect state

Each phase uses simple, interpretable rules without any matrix operations. This should improve position control while being much simpler and avoiding the forbidden LQR approach.
</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
# EVOLVE-BLOCK-START
class Controller:
    """
    Adaptive Cross-Coupled Controller with Enhanced Position Centering

    Combines fast stabilization with improved position control through:
    1. State-dependent cross-coupling for better coordination
    2. Direction-gated mid-swing damping for fast recovery
    3. Predictive momentum compensation
    4. Enhanced integral control with stronger position centering
    5. Direct position correction when pole is stable
    """

    def __init__(self):
        # System parameters
        self.m = M_POLE
        self.M = M_CART
        self.l = L_COM
        self.g = G
        self.Mtot = self.M + self.m
        self.denom0 = self.l * (4.0 / 3.0 - self.m / self.Mtot)
        self.b_c = FRICTION_CART
        self.b_j = FRICTION_JOINT

        # Build base A matrix
        A = np.zeros((4, 4))
        A[0, 2] = 1.0
        A[1, 3] = 1.0
        A[3, 1] = self.g / self.denom0
        A[3, 2] = self.b_c / (self.Mtot * self.denom0)
        A[3, 3] = -self.b_j / (self.m * self.l * self.denom0)
        A[2, 1] = -(self.m * self.l / self.Mtot) * A[3, 1]
        A[2, 2] = -self.b_c / self.Mtot - (self.m * self.l / self.Mtot) * A[3, 2]
        A[2, 3] = self.b_j / (self.Mtot * self.denom0)

        # B matrix
        B = np.zeros((4, 1))
        B[2, 0] = 1.0 / self.Mtot + (self.m * self.l) / (self.Mtot**2 * self.denom0)
        B[3, 0] = -1.0 / (self.Mtot * self.denom0)

        # Base Q with cross-coupling terms
        Q = np.diag([4.5, 44.0, 0.6, 3.2])
        Q[1, 3] = 0.8
        Q[3, 1] = 0.8
        R = np.array([[1.0]])

        self.A = A
        self.B = B
        self.K = self.solve_lqr(A, B, Q, R)

        # Enhanced integral control parameters
        self.integral_x = 0.0
        self.K_i = 1.0  # Increased for better position correction

        # Natural frequency for normalized calculations
        self.omega_n = np.sqrt(G / L_COM)

    def solve_lqr(self, A, B, Q, R):
        """Solve continuous-time LQR"""
        from scipy.linalg import solve_continuous_are
        P = solve_continuous_are(A, B, Q, R)
        K = np.linalg.inv(R) @ B.T @ P
        return K

    def get_action(self, state):
        """Adaptive control with enhanced position centering"""
        x, theta, dx, dtheta = state

        # Robust angle normalization
        theta = ((theta + np.pi) % (2 * np.pi)) - np.pi

        state_vec = np.array([x, theta, dx, dtheta])

        # Compute base force
        base_force = -self.K @ state_vec

        # Adaptive gain scheduling
        pos_gain = 1.0 + 0.5 * np.tanh(5.0 * max(0.0, abs(theta) - 0.6))
        vel_gain = 1.0 + 0.3 * np.tanh(4.0 * max(0.0, abs(dtheta) - 1.0))
        adaptive_gain = pos_gain * vel_gain

        force = base_force * adaptive_gain

        # Direction-gated mid-swing damping (0.25-0.85 rad range)
        mid_swing_activation = np.exp(-4.0 * (abs(theta) - 0.5)**2)
        if abs(theta) > 0.25 and abs(theta) < 0.85:
            K_d_midswing = 6.0
            is_returning = 0.5 * (1.0 - np.tanh(5.0 * theta * dtheta))
            midswing_damp = K_d_midswing * dtheta * mid_swing_activation * is_returning
            force = force + midswing_damp

        # Predictive momentum compensation
        sin_theta = np.sin(theta)
        cos_theta = np.cos(theta)

        f_cart = -self.b_c * dx
        f_joint = -self.b_j * dtheta
        temp_est = (force[0] + f_cart + self.m * self.l * dtheta**2 * sin_theta) / self.Mtot
        denominator = self.l * (4.0/3.0 - self.m * cos_theta**2 / self.Mtot)

        theta_acc_est = (self.g * sin_theta - cos_theta * temp_est + f_joint / (self.m * self.l)) / denominator
        dtheta_pred = dtheta + theta_acc_est * DT

        pred_divergence = theta * dtheta_pred / (self.omega_n * L_COM)
        predictive_correction = -0.12 * pred_divergence * np.tanh(2.0 * abs(theta))
        force = force + predictive_correction

        # Swing-up assist for large angles
        if abs(theta) > 0.8:
            swing_activation = np.tanh(6.0 * (abs(theta) - 0.8))
            falling_factor = 1.0 + np.tanh(2.0 * theta * dtheta / (L_COM * self.omega_n))
            u_swing = 8.0 * swing_activation * np.sign(theta) * falling_factor
            force = force + u_swing

        # Enhanced dual-gated integral action with wider gates
        angle_gate = np.tanh(12.0 * (0.12 - abs(theta)))
        velocity_gate = np.tanh(8.0 * (1.2 - abs(dtheta)))
        integral_gate = angle_gate * velocity_gate

        if integral_gate > 0.05:
            self.integral_x += x * DT
            self.integral_x = np.clip(self.integral_x, -2.0, 2.0)
        else:
            self.integral_x *= 0.96

        integral_force = self.K_i * integral_gate * self.integral_x
        force = force - integral_force

        # Direct position centering when pole is stable
        stability_factor = np.exp(-8.0 * (theta**2 + 0.4 * dtheta**2))
        if stability_factor > 0.4:
            position_correction = -0.6 * x * stability_factor - 0.3 * dx * stability_factor
            force = force + position_correction

        return float(force[0])
=======
# EVOLVE-BLOCK-START
class Controller:
    """
    Phase-Based Rule Controller

    Philosophy: "Different phases need fundamentally different control strategies"

    Four distinct phases with completely different control logic:
    1. EMERGENCY: Aggressive cart movement to catch falling pole
    2. RECOVERY: Guided energy management to bring pole vertical
    3. BALANCING: Precise position control while maintaining balance
    4. HOLD: Minimal intervention to maintain perfect state
    """

    def __init__(self):
        # System parameters for physics calculations
        self.m = M_POLE
        self.M = M_CART
        self.l = L_COM
        self.g = G
        self.Mtot = self.M + self.m

        # Position integral for final centering
        self.integral_x = 0.0

        # Phase tracking
        self.last_phase = "UNKNOWN"

    def get_action(self, state):
        """Phase-based control with simple, interpretable rules"""
        x, theta, dx, dtheta = state

        # Robust angle normalization
        theta = ((theta + np.pi) % (2 * np.pi)) - np.pi

        # Determine current phase based on state
        if abs(theta) > 0.7:
            current_phase = "EMERGENCY"
        elif abs(theta) > 0.3:
            current_phase = "RECOVERY"
        elif abs(theta) > 0.05 or abs(dtheta) > 0.5:
            current_phase = "BALANCING"
        else:
            current_phase = "HOLD"

        # Apply phase-specific control strategy
        if current_phase == "EMERGENCY":
            # EMERGENCY: Save the pole from falling!
            # Move cart aggressively toward where pole is falling
            urgency = min(3.0, abs(theta) / 0.3)  # Scale urgency with angle
            target_x = x + 2.0 * np.sign(theta) * urgency  # Move in falling direction
            force = 15.0 * (target_x - x) - 5.0 * dx  # PD control to target

        elif current_phase == "RECOVERY":
            # RECOVERY: Guide pole back to vertical with energy management
            # Push cart to create torque that brings pole up
            if theta * dtheta > 0:
                # Pole moving away from vertical - resist
                force = -8.0 * np.sign(theta) * abs(theta) - 2.0 * dx
            else:
                # Pole moving toward vertical - assist
                force = 12.0 * np.sign(theta) * abs(theta) - 1.5 * dx

        elif current_phase == "BALANCING":
            # BALANCING: Focus on position control while maintaining balance
            # Primary goal: center the cart
            position_force = -4.0 * x - 2.0 * dx

            # Secondary goal: keep pole vertical
            angle_force = -25.0 * theta - 8.0 * dtheta

            # Blend them, prioritizing angle when it's larger
            angle_weight = min(1.0, abs(theta) / 0.1)
            force = (1.0 - angle_weight) * position_force + angle_weight * angle_force

            # Update integral for position centering
            self.integral_x += x * DT
            self.integral_x = np.clip(self.integral_x, -1.0, 1.0)
            force -= 1.5 * self.integral_x

        else:  # HOLD phase
            # HOLD: Minimal intervention to maintain perfect state
            # Very gentle corrections only
            force = -1.0 * x - 0.5 * dx - 5.0 * theta - 2.0 * dtheta

            # Slowly decay integral to prevent windup
            self.integral_x *= 0.99
            force -= 0.5 * self.integral_x

        # Phase transition smoothing
        if current_phase != self.last_phase:
            # Smooth transitions to avoid jerky behavior
            force *= 0.7
        self.last_phase = current_phase

        return float(force)
>>>>>>> REPLACE
</DIFF>